# test task similarity images clustering 

Решение тестового задания 

#### Визуализация результатов разделения сохраняется в папку ``groped``
Можно скачать тут - https://disk.yandex.ru/d/p8-asn55kgoIXA


#### Код для разделения похожих изображений в ``clustering.ipynb`` (создает папку `grouped`)
Для воспроизведения результатов в корень проекта нужно положить папку с изображениями (`database_T2`) и запустить код в 
ноутбуке

### Критерий похожести:

По изображениям видно, что похожие изображения - это изображения снятые в одном месте, примерно в одно время (возможно вырезаны из одного видео фала). Поэтому основной визуальный критерий похожести - 
изображение одного и того же места объекта. 

Так как цвета на некоторых изображениях могут меняться достаточно цветовые гистограммы как признаки похожести оказались не лучшим вариантом 

 Как признак близости использовалось косинусное расстояние между векторами извлеченными из изображений с помощью пред-обученной нейронной сети.


### Классические фичи/признаки: 
1. попробовал извлекать цветовые гистограммы, но на некоторых похожих фото
цвет меняется резко, для них этот подход работает плохо. 
2. можно попробовать использовать ключевые точки (не успел), скорее всего, будет работать хуже, чем признаки из нейронных сетей (так как ракурс меняется достаточно сильно на некоторых изображениях)

### DL признаки:
1. пред-обученный resnet. Работает хорошо
2. пред-обученный clip. Тоже визуально работает хорошо. Без разметки (или количества классов) детально сравнить эти две сети сложно.



## Решение

С помощью библиотеки jina(DocumentArray) для визуализации картинок и эмбеддингов, сравнил работу трех подходов для извлечения признаков - цветовые гистограммы (opencv), resnet50 и clip. Цветовые гистограммы на многих изображениях справлялись, но на тех где резко менялся цвет, ожидаемо, не справлялись. Resnet и CLIP оба показали (визуально) хорошие результаты. Дальше решил продолжить с resnet (для простоты). (Эксперименты проводил в `research.ipynb`). Поиск по извлеченным признакам 
выполнялся с использованием `faiss` (поиск выполнялся по векторно для удобства дебага). Далеее разделение изображений 
происходило на основе расстояния между векторами признаков (по трешхолду). Так же пробовал разделение через кластеризацию
векторов, но из-за отсутствия лейблов (или количества классов) результаты были визуально хуже, чем при разделении по 
трешхолду. 

Подход с извлечением векторов и поиском по ним был выбран с мыслью, что хоть мы и можем разделить 366 картинок сравнением 
каждой с каждой - такой подход был бы не масштабируемым.

Далее для читаемости и удобства вынес код для извлечения фичей в .py файлы. И в ноутбуке `clustering.ipynb` написал класс для разделения похожих изображений. Визуализация сохраняется в папку `grouped` (если такой нет, она создается)


# requirements
Для воспроизведения результатов нужно установить библиотеки из `requirements.txt`
